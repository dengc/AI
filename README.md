# AI

@(IT Studies)


-------------------

[TOC]

## Intro
-------------------

### Defination
><b>Think & act (behavior) like human/rationally

* Science - knowledge
* Engineering - problem solving


### Characteristics
1. Accessible: know the state
2. Deterministic: know how to solve problem
3. Episodic: depend on previous episode
4. Static: dynamic if the environment changes during deliberation 
5. Discrete vs. continuous: Chess vs. driving 
6. Hostile 


### Intelligent Agent


## Uninformed  Search
-------------------

### Breadth-first
> put successors at the end of queue

### Uniform-cost
>insert in order of increasing path cost
* min cost first, then G

### Depth-first
> put successors in front of the queue -> stack

### Depth-limited
> depth-first search with depth limit l 

### Iterative deepening
> combine dfs & bfs, Depth-limited çš„ l ä¸æ–­å¢åŠ 

### Bidirectional search
> from start and goal search, to the middle

![Searches](./Searches Comparasion.png)

## Informed  Search
-------------------
### Best First
> insert successors in decreasing order of desirability

#### Greedy search
> è¯„ä»·å‡½æ•°f(n), é€‰æ‹©æœ€å°çš„f(n)
    > - f(n) = h(n), h(n) -> estimate of cost from n to goal
    > - è·ç¦»çš„è¯ï¼Œä¸ºnåˆ°goalçš„ straight-line distance  

#### A*
> f(n) = g(n) + h(n)ï¼Œg(n) ä¸ºä»èµ·ç‚¹åˆ°nçš„å·²æ¶ˆè€—è·ç¦»
    > - if admissible, h(n) <= h*(n) where h*(n) is the true cost from n. ï¼ˆé¢„æµ‹ä¸å¯èƒ½å¤§äºçœŸå®æƒ…å†µï¼‰


### Hill-climbing

### Simulated annealing
> 1.     é¦–å…ˆä¾¿æ˜¯åˆå§‹åŒ–å·¥ä½œï¼Œè®¾ç½®åˆå§‹æ¸©åº¦ï¼ˆtemperatureï¼‰,è·å¾—ä¸€ä¸ªéšæœºçš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶å°†å…¶è®¾ç½®ä¸ºå½“å‰è§£å†³æ–¹æ¡ˆï¼ˆcur_solï¼‰ã€‚
2.     å¦‚æœæ¸©åº¦å¤§äº0ï¼Œå¤„ç†cur_solï¼ˆperturbå¤„ç†ï¼Œæ¯”å¦‚éšæœºè°ƒæ¢æ–¹æ¡ˆä¸­æ­¥éª¤æ‰§è¡Œé¡ºåºç­‰ï¼‰ï¼Œå¾—åˆ°æ–°æ–¹æ¡ˆï¼ˆnew_solï¼‰ï¼›å¦‚æœæ¸©åº¦å°äº0ï¼Œç»“æŸç®—æ³•ã€‚
3.     æ¯”è¾ƒå½“å‰æ–¹æ¡ˆå’Œæ–°æ–¹æ¡ˆçš„æ¶ˆè€—ï¼ˆdeltaE = cost(new_sol) â€“ cost(cur_sol)ï¼‰ã€‚
4.     å¦‚æœdeltaEå°äº0åˆ™è¡¨æ˜æ–°æ–¹æ¡ˆæ¯”å½“å‰æ–¹æ¡ˆä¼˜ç§€ï¼Œå°†æ–°æ–¹æ¡ˆè®¾ç½®ä¸ºå½“å‰æ–¹æ¡ˆï¼Œé™æ¸©ï¼Œåˆ™ç»§ç»­æ‰§è¡Œæ­¥éª¤2ã€‚
5.     æ ¹æ®å…¬å¼`p = exp(-detaE/T)`ã€‚è®¡ç®—på°†å…¶ä¸ä»¥å°äº1çš„æ­£éšæœºæ•°æ¯”è¾ƒã€‚å¦‚æœpå¤§äºéšæœºæ•°ï¼Œæ­£å°†æ–°æ–¹æ¡ˆè®¾ç½®ä¸ºå½“å‰æ–¹æ¡ˆï¼Œé™æ¸©ç»§ç»­æ‰§è¡Œæ­¥éª¤2ï¼›å¦‚æœpå°äºéšæœºæ•°ï¼Œåˆ™é™æ¸©ç›´æ¥æ‰§è¡Œæ­¥éª¤2ã€‚
è¿™ä¸ªæµç¨‹å¯ä»¥ç®€å•çš„ç†è§£ï¼šä¸æ–­è·å–æ–°æ–¹æ¡ˆï¼Œå’Œå½“å‰æ¯”è¾ƒï¼Œå¦‚æœä¼˜äºå½“å‰æ–¹æ¡ˆï¼Œå–æ–°æ–¹æ¡ˆä¸ºå½“å‰æ–¹æ¡ˆï¼›å¦‚æœåŠ£äºå½“å‰æ–¹æ¡ˆï¼Œåˆ™ç»™äºˆå®ƒä¸€ä¸ªæœºä¼šæˆä¸ºå½“å‰æ–¹æ¡ˆï¼Œè¿™ä¸ªæœºä¼šçš„æ¦‚ç‡å–å†³äºå½“å‰çš„æ¸©åº¦å’Œå®ƒä¸å½“å‰æ–¹æ¡ˆä¹‹é—´çš„å·®è·ã€‚


## Game Playing
-------------------

### Minimax
![Alt text](./minimax.png)

1. æ²¡åŠæ³•cover all the treesæ—¶å€™, cut-off, æŒ‰è‡ªå®šä¹‰åˆ†ç®— (æ£‹ç›˜ä¸Šå‰©çš„å­)
2. a-b pruning
> Same basic idea as minimax, but prune (cut away) branches of the tree that we know will not contain the solution
>  a: Best choice so far for MAX  
>  b: Best choice so far for MIN 
![Alt text](./a-b_minimax.png)

3. for Nondeterministic games: ä¹˜ä»¥chance


## Constraint Satisfaction Problems (CSP)
-------------------

### Attributes
- variables
- domain: values, one for each variable
- constraints: over value of variables

### Example
1. map coloring
    - variables: each area
    - domain: colors {}
    - constraints: adjacent regions must have different colors
2. sudoku
    - variables: each square
    - domain: 1-9
    - constraints: each column, each row, and each of the nine 3Ã—3 sub-grids that compose the grid contain all of the digits from 1 to 9 

### Backtracking 
> DFS with one variable assigned per node

1. Tie-breaker first: Most constraining variable
2. AC-3: check if every node is arc-consistent --> **network arc-consistency** or **no solve**  
3. Forward checking: see what legal values left

### Local Search
> min-conflicts heuristic: choose value that violates the fewest constraints == ç§»åŠ¨violateæœ€å¤šçš„


## Tips
-------------------
presentation (state): keep track of / coord

The constraints restrict the domain 
SA is optimal
GA == tsp

admissible heuristic: è‡ªå·±æƒ³ä¸ªæ ‡å‡†:
h(n) == missing numbers/ numbers of div need to be moved/ straight line/ manhattan




## logic
-------------------
### Entail
KB |= a
(å……åˆ† |= å¿…è¦)

### Inference
KB |â€“i a  = sentence a can be derived from KB using procedure i 
- Sound: whenever KB |â€“i a then KB |= a is true,   does not infer false statements
- Complete: whenever KB |= a then KB |â€“i a,   derives any sentence that is entailed,  a plan where every precondition is achieved

### Propositional Logic
symbol, syntax, semantic 
> A => B = (Â¬A) V B
Â¬(A => B) = A ^ (Â¬B)
A <==>B = (A => B) ^ (B => A)

We saw that propositional logic is limited because it only makes the ontological commitment that the world consists of facts. 

### First-order logic
proof: ç­‰å·å·¦å³ä¸¤è¾¹å¼å­æ¨å¯¼

CNF: ^ ï¼ˆconjunctionï¼‰ / V (disjunction), æœ€å¤–é¢åªæœ‰^ ä¸”åªæœ‰ä¸€ä¸ªvariable
INF: =>, ä»»æ„/å­˜åœ¨

#### English to FOL (E, V, ^ , => ... )
KB |= a  <==>  KB => a  , not (KB ^ éa )
å­˜åœ¨ç”¨^, ä»»æ„ç”¨ =>
exactly one cook: âˆƒ!ğ‘¥ isCook(x)


proof
1. model checking
2. inference rules

Ontology: like database relations



### Forward Chaining 
1. acts like a breadth-first search at the top level, with depth-first sub-searches. 
2. sound and complete, complete for horn KB
3. data-driven reasoning

### Backward Chaining
1. a depth-first search: in any knowledge base of realistic size, many search paths will result in failure
2. not complete due to infinite loops. but sound
3. goal-directed reasoning


### prolog
1. using backward chain
2. No Occurs-Check-> traded soundness for efficiency
3. incomplete not sound, no check for infinite recursion

### Horn Form
1. not more than 1 positive sentence
2. Every Horn clause is not a Definite clause


### Atomic Sentence
no variables, only constant



## Logic & Plan é¢˜ç›®
-------------------

### planning schema:
Action(Paint(b, c), 
Precond: Blank(b) âˆ§ Wet(brush, c)ï¼Œ
Effect: ~ Blank(b) âˆ§ Color(b, c)) 
- Delete literalï¼š åˆ precondä¸­çš„ä¸œè¥¿

if one effect conflicts other's precond, may need another state...

### resolution:
åè¯ï¼šå¼•ç”¨ä¾‹å­: x1/John
or ç”¨å·²æœ‰çš„äº’æ¨ï¼Œæ¨å‡ºç­”æ¡ˆ

### convert to CNF:
1. A => B = (Â¬A) V B : Eliminate â‡’, replace ğœ¶ â‡’ ğœ·, with Â¬ğœ¶ âˆ¨ ğœ·
2. Reduce negation
3. æŠŠå­˜åœ¨çš„å€¼ç”¨aï¼Œbä»£æ›¿ ï¼š âˆƒğ’™ ğ‘¨(ğ’™) âˆ§ ğ‘«(ğ’™) = ğ‘¨(ğ‘²) âˆ§ ğ‘«(ğ‘²) = ğ‘¨(ğ‘²), ğ‘«(ğ‘²) â€“ using Skolemization Constant (ä¸¾ä¾‹)
4. å»æ‰å­˜åœ¨ï¼ŒæŠŠå­˜åœ¨çš„å€¼å˜æˆ f (x), xå…³äºä»»æ„
5. å»æ‰ä»»æ„
6. A V (B ^ C) = (A V B) ^ (A V C) -- (Distributive law)

### Backward Chainingï¼š
ä»ç»“æœå¾€å›æ¨ï¼š å¼•ç”¨ä¾‹å­: {x/USC, y/UCLA}

### Forward Chaining:
ç»“åˆrules æ­£æ¨ å¼•ç”¨ä¾‹å­
6,7 | NicerCampus(USC, UCLA) | x/USC, y/UCLA

### Inference Rule
And-eliminationï¼š å¹¶é›†ä¸­çš„ä¸€ä¸ª
And-introduction: åˆå¹¶
Modus Ponens on å·¦å³ï¼šé¡ºæ¨
modus tollens on å·¦å³ï¼šå€’é€€

### fuzzy logic
and: min


### åˆ¤æ–­é¢˜ï¼š
- Successor-state axioms solve the representational frame problem.
- all things that stay the same from one situation to the next: frame problem
- The completeness theorem states that any sentence entailed by a set of sentences can be proven from that set.
- Soundness of an inference algorithm means that the algorithm doesnâ€™t reach bogus conclusions.
- Entailment can be used to derive true conclusions.
- All sentences in propositional logic can be converted to CNF.
- Some sentences in propositional logic cannot be converted to Horn Form.
- Planning graphs work only for propositional planning problemsâ€” ones with no variables.
- Reification represents a category as an object
- tautology is a sentence that is necessary true in all models.
- An upper ontology can be used for knowledge sharing.
- Generalized Modus Ponens is a sound inference rule, not complete, horn form
- POP is sound, complete, and systematic
- Algorithms exist that return YES to every entailed sentence, but no algorithm exists that also returns NO to every nonentailed sentence


## Bayesian
-----------------------------------
Independent: P(a,b)=P(a) * p(b)
p(a|b) * p(b) = p(b|a) * p(a)
p(d|a) = p(b|a) * p(d|b)

- P(B | H+, L-, E+) 
= Î±P(B, H+, L-, E+) 
= Î±(P(B, H+, L-, Q+, E+) + P(B, H+, L-, Q-, E+))
= Î±(<P(B+) P(H+) P(L- | H+) P(Q+ | B+, H+, L-) P(E+ | Q+),
P(B-) P(H+) P(L- | H+) P(Q+ | B-, H+, L-) P(E+ | Q+)> + <P(B+) P(H+) P(L- | H+) P(Q- | B+, H+, L-) P(E+ | Q-), P(B-) P(H+) P(L- | H+) P(Q- | B-, H+, L-) P(E+ | Q-)>)

- P(a|b,c)
= P(a,b,c) / P(b,c)


## Machine Learning
-----------------------------------
### Decision Tree
Information Gain = æ€»Entropy - (n/m * æ­¤entropy + m-n/m * æ­¤entropy)
split on first: which has highest information gain

### Neural Networks
network output: æ­£ä¸º1ï¼Œè´Ÿä¸º0
number of weights w/bias: (input + 1 )* hidden + (hidden + 1) * output
number of weights without bias: ä¸åŠ 1

### Candidate Elimination
negative example & true negative: æ‰¾ S åä¾‹
positive example & true positive: æ‰¾ G æ­£ä¾‹
negative example & false positiveï¼š æ‰¾ å…¨ æ­£ä¾‹
positive example & false negativeï¼š æ‰¾ å…¨ åä¾‹


## Reinforcement Learning
-----------------------------------
V = æœ€å¤§Î³ ä¹˜ç§¯å’Œå‘¨å›´æ‰€æœ‰æ¯”è¾ƒ (å¯èƒ½åŠ ä¸€ä¸ªreward actionçš„å€¼)
å¾ªç¯çš„è¯ï¼šV = pÎ³R + (1-p)Î³V


## åˆ¤æ–­é¢˜ï¼š
- Bayesian network cover every boolean functions
- Naive Bayes is not a linear classifier
- A single perceptron (finite number training steps) cannot compute the XOR function
- supervised learning is labeled
- reinforcement learning: we do not need to know the transition probabilities before we start, not know the utility function
- NPL: Cocke-Younger-Kasami
- incremental strategy: most vars are 0